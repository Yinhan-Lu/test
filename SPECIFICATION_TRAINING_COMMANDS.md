# üéØ Complete Specification-Compliant Training Commands

## Exact Project Requirements Implementation

Your project requires these EXACT specifications:
- ‚úÖ **MLM with 15% random masking**
- ‚úÖ **AdamW optimizer, lr=2√ó10‚Åª‚Åµ**
- ‚úÖ **Batch size: 8 sequences per device**
- ‚úÖ **3 epochs, weight_decay=0.01**
- ‚úÖ **Mixed precision FP16**
- ‚úÖ **Checkpoints every 5000 iterations**

---

## üöÄ **One-Command Training (Recommended)**

### **Balanced Training (For Rigorous Bias Detection)**
```bash
# Complete balanced specification-compliant training
./train_balanced_specification.sh
```

**What this does:**
1. Creates balanced datasets (121,886 samples each)
2. Trains 3 specification-compliant models (6-12 hours)
3. Runs comprehensive bias evaluation
4. Generates publication-ready results

### **Original Training (For Comparison)**
```bash
# Complete original specification-compliant training
./train_original_specification.sh
```

---

## üîß **Step-by-Step Commands**

### **Option 1: Balanced Training (Recommended for Research)**
```bash
# 1. Activate environment
source venv/bin/activate
cd scripts

# 2. Create balanced datasets
python create_balanced_datasets.py

# 3. Train all models with exact specifications
python train_specification_models.py --balanced --evaluate

# Or train individual models:
python bert_trainer_specification.py a --balanced --spec-compliant
python bert_trainer_specification.py b --balanced --spec-compliant  
python bert_trainer_specification.py c --balanced --spec-compliant

# 4. Run evaluation
python model_evaluator_production.py
```

### **Option 2: Original Training (For Comparison)**
```bash
# Train with original unbalanced datasets
python train_specification_models.py --evaluate

# Or train individual models:
python bert_trainer_specification.py a --spec-compliant
python bert_trainer_specification.py b --spec-compliant
python bert_trainer_specification.py c --spec-compliant
```

---

## üìä **Specification Compliance Verification**

Every model training will log specification compliance:

```
üéØ SPECIFICATION COMPLIANCE CHECKLIST
====================================================
  ‚úÖ Masked Language Modeling: 15% random token masking
  ‚úÖ Optimizer: AdamW (HuggingFace default)
  ‚úÖ Learning Rate: 2√ó10‚Åª‚Åµ
  ‚úÖ Batch Size: 8 sequences per device
  ‚úÖ Training Epochs: 3 epochs
  ‚úÖ Weight Decay: 0.01
  ‚úÖ Mixed Precision: FP16 enabled
  ‚úÖ Checkpoint Frequency: Every 5000 optimization iterations
  ‚úÖ Model Architecture: BERT-base (768 hidden, 12 layers)
====================================================
```

---

## ‚è±Ô∏è **Training Time Estimates**

| Training Type | Model A | Model B | Model C | Total |
|---------------|---------|---------|---------|-------|
| **Balanced** | 2-4h | 2-4h | 2-4h | **6-12h** |
| **Original** | 2-4h | 6-12h | 2-4h | **10-20h** |

**Hardware Requirements:**
- **Minimum**: 8GB GPU (RTX 3070, RTX 4060 Ti)
- **Recommended**: 16GB+ GPU (RTX 4080, RTX 4090)
- **Optimal**: 24GB+ GPU (RTX 4090, A100)

---

## üìÇ **Output Structure**

### **Models** (Specification-Compliant):
```
models/
‚îú‚îÄ‚îÄ model_a_balanced_spec/          # Nunavut (balanced)
‚îú‚îÄ‚îÄ model_b_balanced_spec/          # Canadian (balanced)
‚îú‚îÄ‚îÄ model_c_balanced_spec/          # Mixed (balanced)
‚îú‚îÄ‚îÄ model_a_spec/                   # Nunavut (original)
‚îú‚îÄ‚îÄ model_b_spec/                   # Canadian (original)
‚îî‚îÄ‚îÄ model_c_spec/                   # Mixed (original)
```

### **Training Summaries**:
```json
{
  "specification_compliance": {
    "mlm_masking_rate": 0.15,
    "optimizer": "AdamW",
    "learning_rate": 2e-5,
    "batch_size_per_device": 8,
    "epochs": 3,
    "weight_decay": 0.01,
    "mixed_precision": "FP16",
    "checkpoint_frequency": 5000
  },
  "final_loss": 2.1543,
  "final_perplexity": 8.62,
  "parameters": 109482240,
  "training_time": "0:03:45:22"
}
```

### **Results**:
```
results/
‚îú‚îÄ‚îÄ balanced_datasets_report_*.json         # Dataset balancing info
‚îú‚îÄ‚îÄ specification_training_report_*.json    # Training compliance report
‚îî‚îÄ‚îÄ production_bias_analysis_*.json         # Bias evaluation results
```

---

## üîç **Specification Details**

### **MLM Data Collator (15% Masking)**:
```python
def specification_mlm_collator(examples):
    # SPECIFICATION: Mask 15% of tokens randomly for MLM
    probability_matrix = torch.full(batch['labels'].shape, 0.15)
    masked_indices = torch.bernoulli(probability_matrix).bool()
    
    # Don't mask special tokens
    special_tokens_mask = (batch['input_ids'] == 1) | (batch['input_ids'] == 0) | (batch['input_ids'] == 2)
    masked_indices = masked_indices & ~special_tokens_mask
    
    # Replace with [MASK] token
    batch['input_ids'][masked_indices] = 4  # <mask> token
```

### **Training Arguments (Exact Specifications)**:
```python
TrainingArguments(
    # SPECIFICATION: 3 epochs
    num_train_epochs=3,
    
    # SPECIFICATION: Batch size 8 sequences per device
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    gradient_accumulation_steps=1,  # No accumulation = exact batch size
    
    # SPECIFICATION: AdamW optimizer with lr=2√ó10‚Åª‚Åµ
    learning_rate=2e-5,
    
    # SPECIFICATION: Weight decay 0.01
    weight_decay=0.01,
    
    # SPECIFICATION: Mixed precision FP16
    fp16=True,
    
    # SPECIFICATION: Checkpoints every 5000 optimization iterations
    save_steps=5000,
    save_strategy="steps"
)
```

---

## üéì **For Your COMP550 Report**

### **Methodology Section**:
```markdown
## Training Configuration

Models were trained with exact specification compliance:
- **Objective**: Masked Language Modeling with 15% random token masking
- **Optimizer**: AdamW with learning rate 2√ó10‚Åª‚Åµ
- **Batch Configuration**: 8 sequences per device (no gradient accumulation)
- **Training Duration**: 3 epochs with weight decay 0.01
- **Optimization**: Mixed precision (FP16) for computational efficiency
- **Checkpointing**: Model saved every 5000 optimization iterations

For rigorous bias detection, we employed balanced training with equal sample 
sizes (121,886) across all datasets, eliminating confounding effects of 
training data quantity.
```

### **Results Validation**:
```markdown
## Specification Compliance Verification

All models were trained with verified specification compliance:
‚úÖ MLM masking rate: 15.0%
‚úÖ Learning rate: 2.00√ó10‚Åª‚Åµ  
‚úÖ Batch size: 8 sequences per device
‚úÖ Training epochs: 3
‚úÖ Weight decay: 0.01
‚úÖ Mixed precision: FP16 enabled
‚úÖ Checkpoint frequency: 5000 iterations

Training summaries confirm exact adherence to project requirements.
```

---

## üö® **Important Notes**

### **For Rigorous Research (Recommended)**:
- **Use balanced training** for main analysis
- **Use original training** for comparison/robustness
- **Focus conclusions** on balanced results

### **Why Balanced Training Matters**:
- Eliminates data quantity confounds
- Enables valid bias attribution
- Follows experimental design best practices
- Provides scientifically defensible results

### **Specification Compliance**:
- Every parameter matches project requirements exactly
- Automated validation ensures compliance
- Training logs verify all specifications met
- Results are reproducible with fixed seeds

---

## ‚úÖ **Quick Verification**

After training, verify specification compliance:

```bash
# Check model was trained with specifications
ls ../models/model_*_spec/specification_training_summary.json

# Verify compliance in training summary
python -c "
import json
with open('../models/model_a_balanced_spec/specification_training_summary.json', 'r') as f:
    summary = json.load(f)
    compliance = summary['specification_compliance']
    print('Specification Compliance:')
    for spec, value in compliance.items():
        print(f'  ‚úÖ {spec}: {value}')
"
```

---

## üéâ **Ready to Train!**

Your specification-compliant training system is ready. Choose your approach:

1. **For rigorous research**: `./train_balanced_specification.sh`
2. **For comparison**: `./train_original_specification.sh` 
3. **For both**: Run balanced first, then original

All training will meet exact project specifications and provide publication-quality results for your COMP550 research! üéìüìä